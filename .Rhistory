var = 900
sd = sqrt(var)/sqrt(n)
alpha = .01
Ha = 620
n = (((qnorm(.1) - qnorm(.99)) * sd)/(600-620))^2
n
sd = sqrt(var)
alpha = .01
Ha = 620
n = (((qnorm(.1) - qnorm(.99)) * sd)/(600-620))^2
n
type_2_err_min_size(alpha = .01, beta = .1, Ho = 600, Ha = 620)
type_2_err_min_size(alpha = .01, beta = .1, Ho = 600, Ha = 620, sd = sqrt(var))
type_2_err_min_size(alpha = .01, beta = .1, Ho = 600, Ha = 620, sigma = sqrt(var))
n
# 2.
Ho = .02
Ha = .021
alpha = .01
power = .95
beta = 1 - power
p = Ho
Ha = .021
alpha = .01
power = .95
beta = 1 - power
n = ((sqrt(p * (1 - p)) * (qnorm(.05) - qnorm(.99)))/(.02 - .021))^@
n = ((sqrt(p * (1 - p)) * (qnorm(.05) - qnorm(.99)))/(.02 - .021))^2
n
library(collegestats)
type_2_err_min_size(alpha = .01, beta = .05, Ho = .02, Ha = .021)
n = ((sqrt(p * (1 - p)) * (qnorm(.05) - qnorm(.99)))/(.02 - .021))^2
n
n = (p * (1 - p))^2 * (qnorm(.05) - qnorm(.99))^2 / (.02 - .021)^2
n
help(function=collegestats)
help(function = "collegestats")
help()
help(collegestats)
help("collegestats"")
help("collegestats")
help(package = "collegestats")
n
n = (p * (1 - p)) * (qnorm(.05) - qnorm(.99))^2 / (.02 - .021)^2
# n = (())
n
n = (sqrt(Ho * (1 - Ho)) * qnorm(.05) - sqrt(Ha * (1 - Ha)) * qnorm(.99))^2 / (.02 - .021)^2
# n = (())
n
# 2.
Ho = .02
Ha = .021
alpha = .01
power = .95
beta = 1 - power
n = (sqrt(Ho * (1 - Ho)) * qnorm(.05) - sqrt(Ha * (1 - Ha)) * qnorm(.99))^2 / (.02 - .021)^2
# n = (())
n
n = (sqrt(Ho * (1 - Ho)) * qnorm(.05) - sqrt(Ha * (1 - Ha)) * qnorm(.99))^2 / (.02 - .021)^2
# n = (())
n
n = (sqrt(Ha * (1 - Ha)) * qnorm(.05) - sqrt(Ho * (1 - Ho)) * qnorm(.99))^2 / (.02 - .021)^2
# n = (())
n
type_2_err_min_size(alpha = .01, beta = .05, Ho = .02, Ha = .021)
library(tidyverse)
vote_data <- read_csv("R-Workspace/vote_data_12_18.csv")
# 1
vote_data <- vote_data %>% filter(YEAR==2016)
library(tidyverse)
vote_data <- read_csv("R-Workspace/vote_data_12_18.csv")
setwd(../)
setwd("../")
library(tidyverse)
vote_data <- read_csv("R-Workspace/vote_data_12_18.csv")
vote_data <- read_csv("vote_data_12_18.csv")
library(tidyverse)
vote_data <- read_csv("vote_data_12_18.csv")
# 1
vote_data <- vote_data %>% filter(YEAR==2016)
vote_data <- read_csv("vote_data_12_18.csv")
# 1
vote_data <- vote_data %>% filter(YEAR==2016)
view(vote_data)
# 2a
pop_p = mean(vote_data$VOTED == 1)
# H_0: true proportion of voters is equal to x_null
pop_p = as.numeric(vote_data %>% summarise(mean(vote_data$VOTED == 1)))
pop_p # our H_0, this is the same as population mean
# 2b
crit_value = qnorm(1 - (1 - .92)/2) # positive and negative z-score
qnorm(.04)
upper_crit = crit_value
lower_crit - -crit_value
lower_crit - -1 * crit_value
# 2b
crit_value = qnorm(1 - (1 - .92)/2) # positive and negative z-score
upper_crit = crit_value
lower_crit = -1 * crit_value
# 2c
n = nrow(vote_data)
variance = pop_p * (1-pop_p) / n
sd = sqrt(variance)
var_x = var(vote_data$VOTED)  # find variance of sample
var_x = var_x * (n - 1) / n
sd_x = sqrt(var_x)
view(vote_data)
library(tidyverse)
vote_data <- read_csv("vote_data_12_18.csv")
# 1
vote_data <- vote_data %>% filter(YEAR==2016)
view(vote_data)
# 2a
pop_p = mean(vote_data$VOTED == 1)
# 2b
crit_value = qnorm(1 - (1 - .92)/2) # positive and negative z-score
upper_crit = crit_value
lower_crit = -1 * crit_value
# 2c
n = nrow(vote_data)
variance = pop_p * (1-pop_p) / n
sd = sqrt(variance)
p_hat = vector(mode = "numeric", length = 10000)
upper_bound = vector(mode = "numeric", length = 10000)
lower_bound = vector(mode = "numeric", length = 10000)
conf_interval_test = vector(mode = "numeric", length = 10000)
for (i in 1:10000) {
samp = vote_data %>% sample_n(30)
samp_mean = mean(samp$VOTED == 1)
samp_sd = sqrt((samp_mean * (1 - samp_mean)/30))
samp_sd
samp_std_err = samp_sd/sqrt(30)
z_score = qnorm(1 - (1 - .92)/2)
upper = samp_mean + z_score * samp_sd
lower = samp_mean - z_score * samp_sd
# set the array with this sampole's values
p_hat[i] = samp_mean
upper_bound[i] = upper
lower_bound[i] = lower
conf_interval_test[i] = pop_p < upper & pop_p > lower
}
sim_results = data.frame(p_hat, upper_bound, lower_bound, conf_interval_test)
view(sim_results)
# when I ran this, I obtained about 92.6% of samples' intervals contained E[X], which is close to 92% (expected)
result = mean(sim_results$conf_interval_test == 1)
result
p_hat1 = vector(mode = "numeric", length = 10000)
upper_bound1 = vector(mode = "numeric", length = 10000)
lower_bound1 = vector(mode = "numeric", length = 10000)
conf_interval_test1 = vector(mode = "numeric", length = 10000)
pop_p_new = pop_p - .05
for (i in 1:10000) {
samp1 = vote_data %>% sample_n(30)
samp_mean1 = mean(samp1$VOTED == 1)
samp_sd1 = sqrt((samp_mean1 * (1 - samp_mean1)/30))
samp_std_err1 = samp_sd/sqrt(30)
z_score1 = qnorm(1 - (1 - .92)/2)
upper1 = samp_mean1 + z_score1 * samp_sd1
lower1 = samp_mean1 - z_score1 * samp_sd1
# set the array with this sampole's values
p_hat1[i] = samp_mean1
upper_bound1[i] = upper1
lower_bound1[i] = lower1
conf_interval_test1[i] = pop_p_new < upper1 & pop_p_new > lower1
}
sim_results1 = data.frame(p_hat1, upper_bound1, lower_bound1, conf_interval_test1)
result1 = mean(sim_results1$conf_interval_test1 == 1)
# when I ran this, it yielded 86.33%, which is not very close to 92%. This is because our null hypothesis
# has been shifted to the left, so the odds of it fitting inside the interval 92% of the chance is now less
# I propose that if the upper and lower bounds were both shifted by -.05, we would obtain around 92% fit like in part d
result1
# 2f
# 2f
# Technically we still calculated a 92% confidence interval. However, the interpretation changes from in part d:
# 2f
# Technically we still calculated a 92% confidence interval. However, the interpretation changes from in part d:
#     "We are 92% confident that the true mean of voters in 2016 is between {lower_bound} to {upper_bound}"
# 2f
# Technically we still calculated a 92% confidence interval. However, the interpretation changes from in part d:
#     "We are 92% confident that the true mean of voters in 2016 is between {lower_bound} to {upper_bound}"
# to in part e:
# 2f
# Technically we still calculated a 92% confidence interval. However, the interpretation changes from in part d:
#     "We are 92% confident that the true mean of voters in 2016 is between {lower_bound} to {upper_bound}"
# to in part e:
#     "We are 92% confident that the true mean of voters in 2016 is between {lower_bound - 0.05} to {upper_bound - 0.05}"
# 2f
# Technically we still calculated a 92% confidence interval. However, the interpretation changes from in part d:
#     "We are 92% confident that the true mean of voters in 2016 is between {lower_bound} to {upper_bound}"
# to in part e:
#     "We are 92% confident that the true mean of voters in 2016 is between {lower_bound - 0.05} to {upper_bound - 0.05}"
# This is because our original confidence interval was centered at our pop_p (population mean), but since we subtract 0.05
# 2f
# Technically we still calculated a 92% confidence interval. However, the interpretation changes from in part d:
#     "We are 92% confident that the true mean of voters in 2016 is between {lower_bound} to {upper_bound}"
# to in part e:
#     "We are 92% confident that the true mean of voters in 2016 is between {lower_bound - 0.05} to {upper_bound - 0.05}"
# This is because our original confidence interval was centered at our pop_p (population mean), but since we subtract 0.05
# from the null hypothesis, our 92% confidence interval is now centered at our original population mean - 0.05.
# 2f
# Technically we still calculated a 92% confidence interval. However, the interpretation changes from in part d:
#     "We are 92% confident that the true mean of voters in 2016 is between {lower_bound} to {upper_bound}"
# to in part e:
#     "We are 92% confident that the true mean of voters in 2016 is between {lower_bound - 0.05} to {upper_bound - 0.05}"
# This is because our original confidence interval was centered at our pop_p (population mean), but since we subtract 0.05
# from the null hypothesis, our 92% confidence interval is now centered at our original population mean - 0.05.
# Thus, by subtracting 0.05 from the upper and lower bounds, we obtain a 92% confidence interval once again.
# 2f
# Technically we still calculated a 92% confidence interval. However, the interpretation changes from in part d:
#     "We are 92% confident that the true mean of voters in 2016 is between {lower_bound} to {upper_bound}"
# to in part e:
#     "We are 92% confident that the true mean of voters in 2016 is between {lower_bound - 0.05} to {upper_bound - 0.05}"
# This is because our original confidence interval was centered at our pop_p (population mean), but since we subtract 0.05
# from the null hypothesis, our 92% confidence interval is now centered at our original population mean - 0.05.
# Thus, by subtracting 0.05 from the upper and lower bounds, we obtain a 92% confidence interval once again.
################LECTURE PROBLEMS#################
alpha = .08
beta = .15
Ho = .5
Ha = .55
n = (sqrt(Ha * (1 - Ha)) * qnorm(beta) - sqrt(Ho * (1 - Ho)) * qnorm(1 - alpha))^2/(Ho - Ha)^2
################LECTURE PROBLEMS#################
alpha = .08
beta = .15
Ho = .5
Ha = .55
n = (sqrt(Ha * (1 - Ha)) * qnorm(beta) - sqrt(Ho * (1 - Ho)) * qnorm(1 - alpha))^2/(Ho - Ha)^2
n
library(collegestats)
type_2_err_min_size(alpha = alpha, beta = beta, Ho = Ho, Ha = Ha)
#q2
Ho = 5000
sd = 1000
Ha = 5300
alpha = .11
beta = .02
n = (((qnorm(beta) - qnorm(1 - alpha)) * sd)/(Ho - Ha))^2
n
#q2
Ho = 5000
sd = 1000
Ha = 5300
alpha = .11
beta = .02
n = (((qnorm(beta) - qnorm(1 - alpha)) * sd)/(Ho - Ha))^2
n
type_2_err_min_size(alpha = alpha, beta = beta, Ho = Ho, Ha = Ha, sigma = sd)
mu_null - mu_alt + (sigma/sqrt(N)) * qnorm(1 - alpha)
# assumes testing that Ha is greater than Ho
power <- power(mu_null, mu_alt, alpha, sigma, N) {
mu_null - mu_alt + (sigma/sqrt(N)) * qnorm(1 - alpha)
}
upper = mu_null + sigma/sqrt(N) * qnorm(1 - alpha)
# assumes testing that Ha is greater than Ho
power <- function(mu_null, mu_alt, alpha, sigma, N) {
upper = mu_null + sigma/sqrt(N) * qnorm(1 - alpha)
}
# assumes testing that Ha is greater than Ho
power <- function(mu_null, mu_alt, alpha, sigma, N) {
upper = mu_null + sigma/sqrt(N) * qnorm(1 - alpha)
return(pnorm((upper - mu_alt)/(sigma/sqrt(N))))
}
1 - power(50000, 60000, .05, 50000, 100)
library("collegestats")
type_2_err(H0 = 50000, Ha = ">", p = 60000, n = 100, sigma = 50000)
type_2_err(Ho = 50000, Ha = ">", p = 60000, n = 100, sigma = 50000)
type_2_err(Ho = 50000, Ha = ">", p = 60000, n = 100, alpha = .05, sigma = 50000)
type_2_err(Ho = 50000, Ha = ">", p = 60000, n = 100, sigma = 50000)
type_2_err(Ho = 50000, Ha = ">", p = 60000, n = 100, alpha = .05, sigma = 50000)
1 - type_2_err(Ho = 50000, Ha = ">", p = 60000, n = 100, alpha = .05, sigma = 50000)
1 - power(50000, 60000, .05, 50000, 100)
#' the actual probability/mean, sample size, and significance level alpha
#'
#' @param Ho Null hypothesis
#' @param Ha Direction of the test, valid arguments are either "<", ">", or "!="
#' @param mu_alt True probability
#' @param n Sample size
#' @param alpha Significance level/Type I error probability/alpha level
#' @param sigma (Optional) population standard deviation
#' @return probability of Type II error
#' @export
type_2_err <- function(Ho, Ha, mu_alt, n, alpha, sigma = NULL) {
if(is.null(sigma)) {
message("You have not specified an optional population sd. This is usually when working with probabilities.")
# 1-sided test with Ha = greater than some value
if(Ha == ">") {
z = qnorm(1 - alpha)
sd = sqrt(Ho * (1 - Ho)/n)
upper = Ho + z * sd
B = pnorm((upper - mu_alt)/sqrt(mu_alt * (1 - mu_alt)/n))
return(B)
}
else if(Ha == "<") {
z = qnorm(1 - alpha)
sd = sqrt(Ho * (1 - Ho)/n)
lower = Ho - z * sd
z_less = pnorm((lower - mu_alt)/sqrt(mu_alt * (1 - mu_alt)/n))
B = 1 - z_less
return(B)
}
else if(Ha == "!=") {
z = qnorm(1 - (alpha)/2)
sd = sqrt(Ho * (1 - Ho)/n)
lower = Ho - z * sd
upper = Ho + z * sd
z_less = pnorm((lower - mu_alt)/sqrt(mu_alt * (1 - mu_alt)/n))
z_greater = 1 - pnorm((upper - mu_alt)/sqrt(mu_alt * (1 - mu_alt)/n))
B = z_greater - z_less
return(B)
}
else {
return(cat(paste("Usage: please specify a valid Ha value\nOptions: Ha = \"<\", \">\", \"!=\"")))
}
}
# sigma given, working with numerical values
else {
if(Ha == ">") {
z = qnorm(1 - alpha)
sd = sigma/sqrt(n)
upper = Ho + z * sd
B = pnorm((upper - mu_alt)/sd)
return(B)
}
else if(Ha == "<") {
z = qnorm(1 - alpha)
sd = sigma/sqrt(n)
lower = Ho - z * sd
z_less = pnorm((lower - mu_alt)/sd)
B = 1 - z_less
return(B)
}
else if(Ha == "!=") {
z = qnorm(1 - (alpha)/2)
sd = sigma/sqrt(n)
lower = Ho - z * sd
upper = Ho + z * sd
z_less = pnorm((lower - mu_alt)/sqrt(mu_alt * (1 - mu_alt)/n))
z_greater = pnorm((upper - mu_alt)/sd)
B = z_greater - z_less
return(B)
}
else {
return(cat(paste("Usage: please specify a valid Ha value\nOptions: Ha = \"<\", \">\", \"!=\"")))
}
}
}
setwd("collegestats")
devtools::document()
rm(list = c("type_2_err"))
devtools::document()
power <- function(Ho, Ha, mu_alt, n, alpha, sigma = NULL) {
return 1 - type_2_err(Ho = Ho, Ha = Ha, mu_alt = mu_alt, n = n, alpha = alpha, sigma = sigma)
}
power <- function(Ho, Ha, mu_alt, n, alpha, sigma = NULL) {
return(1 - type_2_err(Ho = Ho, Ha = Ha, mu_alt = mu_alt, n = n, alpha = alpha, sigma = sigma))
}
#' (optionally) the population standard deviation
#'
#' @param Ho Null hypothesis
#' @param Ha Direction of the test, valid arguments are either "<", ">", or "!="
#' @param mu_alt True mean or probability
#' @param n Sample size
#' @param alpha Significance level/Type I error probability/alpha level
#' @param sigma (Optional) population standard deviation
#' @return probability of Type II error
#' @export
power <- function(Ho, Ha, mu_alt, n, alpha, sigma = NULL) {
return(1 - type_2_err(Ho = Ho, Ha = Ha, mu_alt = mu_alt, n = n, alpha = alpha, sigma = sigma))
}
devtools::document()
rm(list = c("power"))
devtools::document()
setwd("../")
devtools::install_github("azc242/collegestats")
library(tidyverse)
nyc = reac_csv("midterm_1_data.csv")
nyc = read_csv("midterm_1_data.csv")
nyc = read_csv("/Midterm 2/midterm_1_data.csv")
nyc = read_csv("Midterm 2/midterm_1_data.csv")
var = 7457806356
sd = sqrt(var)
z_score = qnorm(1 - (1 - 84.4)/2)
z_score = qnorm(1 - (1 - .844)/2)
view(nyc)
samp_mean = mean(nyc$Income)
lower = samp_mean - z_score * sd
lower = samp_mean - z_score * sd
upper = samp_mean + z_score * sd
H0 = 53594
z_lower = (H0 - lower) / sd
z_upper = (H0 - upper) / sd
p_value = pnorm(z_lower)
p_value = pnorm(z_lower) + (1 - pnorm(z_upper))
alpha = 1 - .884
p_value = (1 - pnorm(z_lower)) + ( pnorm(z_upper))
alpha = 1 - .884
sd = var  / sqrt(1000)
library(azc242/collegestats)
library("azc242/collegestats")
package("azc242/collegestats")
package("azc242/collegestats")
devtools::install_github("azc242/collegestats")
install.packages("devtools")
devtools::install_github("azc242/collegestats")
install.packages("devtools")
devtools::install_github("azc242/collegestats")
library(collegestats)
library(tidyverse)
library(collegestats)
z_test_neq(H0 = 53594, sigma = sqrt(7457806356), alpha = 1 - .844, samp_size = 1000, x_bar = samp_mean)
var = 7457806356
sd = sqrt(var / n)
samp_mean = mean(nyc$Income)
z_score = qnorm(1 - (1 - .844)/2)
lower = samp_mean - z_score * sd
upper = samp_mean + z_score * sd
var = 7457806356
sd = sqrt(var / 1000)
samp_mean = mean(nyc$Income)
z_score = qnorm(1 - (1 - .844)/2)
lower = samp_mean - z_score * sd
upper = samp_mean + z_score * sd
var = 7457806356
sd = sqrt(var / 1000)
samp_mean = mean(nyc$Income)
z_score = qnorm(1 - (1 - .844)/2)
lower = samp_mean - z_score * sd
upper = samp_mean + z_score * sd
p_value = (1 - pnorm(z_upper)) + ( pnorm(z_lower))
samp_size
z_test_neq(H0 = 53594, sigma = sqrt(7457806356), alpha = 1 - .844, samp_size = 1000, x_bar = samp_mean)
lower = H0 - z_score * sd
upper = H0 + z_score * sd
H0 = 53594
z_lower = (H0 - lower) / sd
z_upper = (H0 - upper) / sd
p_value = (1 - pnorm(z_upper)) + ( pnorm(z_lower))
z_lower = (samp_mean - H0) / sd
p_value = 2 * (1 - pnorm(abs(z_lower)))
alpha = 1 - .884
lower = samp_mean - z_score * sd
upper = samp_mean + z_score * sd
library(tidyverse)
# library(collegestats)
nyc = read_csv("Midterm 2/midterm_1_data.csv")
var = 7457806356
sd = sqrt(var / 1000)
samp_mean = mean(nyc$Income)
# 1 find upper bound of 84.4 percent confidence interval
alpha = 1 - .844
z_score = qnorm(1 - (1 - .844)/2)
lower = samp_mean - z_score * sd
# 2 find upper bound of 84.4 percent confidence interval
upper = samp_mean + z_score * sd
# 3 test H0 = 53594 and find p-value
H0 = 53594
z = (samp_mean - H0) / sd
p_value = 2 * (1 - pnorm(abs(z)))
library(collegestats)
z_test_neq(H0 = 54135, sigma = sqrt(8697650616), alpha = .196, samp_size = 1000, x_bar = 51270.17)
z_test_neq(H0 = 53594, sigma = sqrt(7457806356), alpha = 1 - .844, samp_size = 1000, x_bar = samp_mean)
z_test_neq(H0 = 54135, sigma = sqrt(8697650616), alpha = .196, samp_size = 1000, x_bar = 51270.17)
z_test_neq(H0 = 53594, sigma = sqrt(7457806356), alpha = 1 - .844, samp_size = 1000, x_bar = samp_mean)
library(tidyverse)
nyc = read_csv("Midterm 2/midterm_1_data.csv")
var = 7457806356
sd = sqrt(var / 1000)
samp_mean = mean(nyc$Income)
# 1 find upper bound of 84.4 percent confidence interval
alpha = 1 - .844
z_score = qnorm(1 - (1 - .844)/2)
lower = samp_mean - z_score * sd
lower
# 2 find upper bound of 84.4 percent confidence interval
upper = samp_mean + z_score * sd
upper
# 3 test H0 = 53594 and find p-value
z_test_neq <- function(H0, sigma = NULL, alpha = .05, samp_size, x_bar) {
if(is.null(sigma)) {
samp_sd <- sqrt(H0 * (1 - H0) / samp_size)
upper_crit_value <- H0 + qnorm(1 - alpha/2) * samp_sd
lower_crit_value <- H0 + qnorm(alpha / 2) * samp_sd
reject_H0 = (x_bar < lower_crit_value | x_bar > upper_crit_value)
p_value = 2 * (1 - pnorm(abs(x_bar - H0) / samp_sd))
return(data.frame("Reject H0" = reject_H0,
"p-value" = p_value,
"Upper critical value" = upper_crit_value,
"Lower critical value" = lower_crit_value
))
}
else {
samp_sd <- sqrt(sigma^2 / samp_size)
upper_crit_value <- H0 + qnorm(1 - alpha/2) * samp_sd
lower_crit_value <- H0 + qnorm(alpha / 2) * samp_sd
reject_H0 = (x_bar < lower_crit_value | x_bar > upper_crit_value)
p_value = 2 * (1 - pnorm(abs(x_bar - H0)/samp_sd))
return(data.frame("Reject H0" = reject_H0,
"p-value" = p_value,
"Upper critical value" = upper_crit_value,
"Lower critical value" = lower_crit_value
))
}
}
z_test_neq(H0 = 53594, sigma = sqrt(7457806356), alpha = 1 - .844, samp_size = 1000, x_bar = samp_mean)
devtools::install_github("azc242/collegestats")
help(package = collegestats)
devtools::document()
setwd("collegestats")
devtools::document()\
devtools::document()
rm(list = c("z_test_neq"))
devtools::document()
